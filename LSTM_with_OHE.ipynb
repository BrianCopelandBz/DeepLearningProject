{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM With doc2Vec\n",
    "\n",
    "Transform each basket into a vector, then train a LSTM on the previous baskets to predict the next basket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import collections\n",
    "\n",
    "import random\n",
    "import sqlite3\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getOrders(lowerlimit, upperlimit):\n",
    "    \n",
    "    conn = sqlite3.connect(\"instacart.db\")\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    # Get final order\n",
    "    cur.execute(\"SELECT B.user_id as user_id, A.order_id as order_id, \"\n",
    "                \" B.order_number as order_number, A.product_id as product_id \"\n",
    "                \"FROM products_train A INNER JOIN orders B \"\n",
    "                \" ON A.order_id = B.order_id \"\n",
    "                \"WHERE A.order_id % 100 >= \" + str(lowerlimit) + \\\n",
    "                \" AND A.order_id % 100 <= \" + str(upperlimit) + \";\")\n",
    "    train_order = np.array(cur.fetchall())\n",
    "    \n",
    "    # Get all prior orders\n",
    "    cur.execute( \\\n",
    "        \"SELECT D.user_id as user_id, \"\n",
    "        \"  D.order_id as order_id, \"\n",
    "        \"  D.order_number as order_number, \"\n",
    "        \"  C.product_id as product_id \"\n",
    "        \"FROM products_prior C INNER JOIN ( \"\n",
    "        \"  SELECT DISTINCT A.user_id as user_id,\"\n",
    "        \"    A.order_id as order_id, A.order_number as order_number \"\n",
    "        \"  FROM orders A INNER JOIN ( \"\n",
    "        \"    SELECT DISTINCT user_id FROM orders \"\n",
    "        \"    WHERE eval_set = 'train' \"\n",
    "        \"      AND order_id % 100 >= \" + str(lowerlimit) + \n",
    "        \"      AND order_id % 100 <= \" + str(upperlimit) +\n",
    "        \"    ) B ON A.user_id = B.user_id WHERE A.eval_set = 'prior' \"\n",
    "        \") D ON C.order_id = D.order_id;\")\n",
    "    prior_orders = np.array(cur.fetchall())\n",
    "    \n",
    "    conn.close()\n",
    "    \n",
    "    return train_order, prior_orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2293292, 4)\n",
      "(151348, 4)\n"
     ]
    }
   ],
   "source": [
    "y, x = getOrders(0, 10)\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert purchases to OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "order_dict = dict()\n",
    "\n",
    "for i in range(x.shape[0]):\n",
    "    try:\n",
    "        order_dict[x[i][1]][x[i][2]-1] = 1\n",
    "    except:\n",
    "        order_dict[x[i][1]] = np.zeros((49688))\n",
    "        order_dict[x[i][1]][x[i][2]-1] = 1      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train LSTM Model with Basket Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# create and fit the LSTM network\n",
    "LSTM_model = Sequential()\n",
    "LSTM_model.add(LSTM(100, stateful=True, batch_input_shape=(500, 5, 49688))) # input_shape=(batchsize, timesteps, data_dim)\n",
    "LSTM_model.add(Dense(49688, activation='sigmoid'))\n",
    "LSTM_model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training data in batches of 500 orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting batch 0 of ten.\n",
      "--------------------------------\n",
      "Working on order 0 of this batch...\n",
      "Working on order 100 of this batch...\n",
      "Working on order 200 of this batch...\n",
      "Working on order 300 of this batch...\n",
      "Working on order 400 of this batch...\n"
     ]
    }
   ],
   "source": [
    "for n in range(1):\n",
    "    print(\"Starting batch \" + str(n) + \" of ten.\")\n",
    "    print(\"--------------------------------\")\n",
    "    # Delete x_train / y_train from last iteration, may fail if this is first time through\n",
    "    try:\n",
    "        del y_train\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        del x_train\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    curPosition = 0\n",
    "    \n",
    "    # i iterates over 500 orders \n",
    "    for i in range(500):\n",
    "        \n",
    "        # Print status\n",
    "        if i % 100 == 0:\n",
    "            print (\"Working on order \" + str(i) + \" of this batch...\")\n",
    "        \n",
    "        # New order id coming in:\n",
    "        current_order_id = y[curPosition][1]\n",
    "        current_user_id = y[curPosition][0]\n",
    "        current_user_final_order_number = y[curPosition][2]\n",
    "        \n",
    "        # Initialize One Hot Encoding, one zero for each product\n",
    "        current_user_y = np.zeros((49688))\n",
    "        \n",
    "        # This loop increments curPosition at the end   \n",
    "        while current_order_id == y[curPosition][1]:\n",
    "            \n",
    "            # make the position in current_order_y = 1 for each product_id\n",
    "            # Zero index is product_id == 1, so subtract 1 from the product id\n",
    "            current_user_y[y[curPosition][3] - 1] = 1\n",
    "        \n",
    "            curPosition += 1\n",
    "        \n",
    "\n",
    "        # current_order_y is done, let's make the current_order_x: \n",
    "        # For reference: x and y have format: [user_id, order_id, order_number, product_id]\n",
    "\n",
    "        \n",
    "        # grab this user's prior orders\n",
    "        # Only grab orders where the order number is in the last five orders\n",
    "        prior_orders_products = x[np.where((x[:,0] == current_user_id) & (x[:,2] >= current_user_final_order_number - 5))]\n",
    "\n",
    "        # initialize current_user_x\n",
    "        current_user_x = np.zeros((5, 49688))\n",
    "\n",
    "        # for each product in prior_orders_products, add to current_user_x\n",
    "        for p in prior_orders_products:\n",
    "            \n",
    "            # current_user_x[a][b], where... \n",
    "            # a = timestep = The timestep is order_number - (current_user_final_order_number + 5)\n",
    "            # b = product_id in OHE, minus 1 because of zero indexing\n",
    "            current_user_x[p[2] - (current_user_final_order_number - 5)][p[3] - 1] = 1\n",
    "    \n",
    "        # Assert - current_user_x is done, add to x_train and y_train\n",
    "\n",
    "        # Expand full order to batch dimension\n",
    "        cur_user_x_train = np.expand_dims(current_user_x, axis=0)\n",
    "\n",
    "        # Create x_train or add to it \n",
    "        try: \n",
    "            x_train = np.append(x_train, cur_user_x_train, axis=0)\n",
    "        except:\n",
    "            x_train = cur_user_x_train\n",
    "            \n",
    "        # do the same for y: \n",
    "        # Expand full order to batch dimension\n",
    "        cur_user_y_train = np.expand_dims(current_user_y, axis=0)\n",
    "\n",
    "        # Create x_train or add to it \n",
    "        try: \n",
    "            y_train = np.append(y_train, cur_user_y_train, axis=0)\n",
    "        except:\n",
    "            y_train = cur_user_y_train\n",
    "\n",
    "    # Done creating batch, time to train\n",
    "    #LSTM_model.fit(x_train, y_train, epochs=15, batch_size=x_train.shape[0], verbose=2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2252: UserWarning: Expected no kwargs, you passed 1\n",
      "kwargs passed to function are ignored with Tensorflow backend\n",
      "  warnings.warn('\\n'.join(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "7s - loss: 0.6932\n",
      "Epoch 2/15\n",
      "5s - loss: 0.6927\n",
      "Epoch 3/15\n",
      "5s - loss: 0.6921\n",
      "Epoch 4/15\n",
      "5s - loss: 0.6916\n",
      "Epoch 5/15\n",
      "5s - loss: 0.6909\n",
      "Epoch 6/15\n",
      "5s - loss: 0.6899\n",
      "Epoch 7/15\n",
      "5s - loss: 0.6886\n",
      "Epoch 8/15\n",
      "5s - loss: 0.6867\n",
      "Epoch 9/15\n",
      "5s - loss: 0.6838\n",
      "Epoch 10/15\n",
      "5s - loss: 0.6795\n",
      "Epoch 11/15\n",
      "5s - loss: 0.6733\n",
      "Epoch 12/15\n",
      "5s - loss: 0.6641\n",
      "Epoch 13/15\n",
      "5s - loss: 0.6508\n",
      "Epoch 14/15\n",
      "5s - loss: 0.6317\n",
      "Epoch 15/15\n",
      "5s - loss: 0.6050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7eff97624080>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_model.fit(x_train, y_train, epochs=15, batch_size=x_train.shape[0], verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score the validation orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab validation orders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get validation orders:\n",
    "y_validation, x_validation = getOrders(70, 75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change LSTM Model to accept one order at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# re-define model\n",
    "LSTM_model_predict = Sequential()\n",
    "LSTM_model_predict.add(LSTM(300, stateful=True, batch_input_shape=(1, 5, 100))) # input_shape=(timesteps, data_dim)\n",
    "LSTM_model_predict.add(Dense(100))\n",
    "LSTM_model_predict.add(Dense(100))\n",
    "\n",
    "# copy weights\n",
    "old_weights = LSTM_model.get_weights()\n",
    "LSTM_model_predict.set_weights(old_weights)\n",
    "\n",
    "# compile model\n",
    "LSTM_model_predict.compile(loss='mean_squared_error', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Function to predict for a given order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create function to predict for an offer:\n",
    "# # x_valid is a numpy array of [user_id, order_id, product_id, order_number]\n",
    "# # ...but only for a single user / final validation order\n",
    "# user_id = customer we are predicting a final order for\n",
    "# final_order_number = order_number of the order we are predicting\n",
    "def makePrediction(x_valid, final_order_number):\n",
    "    \n",
    "\n",
    "    # go grab the products for each prior order\n",
    "    # dropping zero index, since we want to subtract at least one from final order num\n",
    "    for j in range(1, 6):\n",
    "\n",
    "        # Reset order string, which will error if this is the first loop \n",
    "        try:\n",
    "            del cur_order_string\n",
    "        except: \n",
    "            pass        \n",
    "\n",
    "        # Make string of products for current order\n",
    "        if final_order_number - j > 0:\n",
    "            for product in [prod for prod in x_valid if prod[2] == final_order_number - j]:\n",
    "                try:\n",
    "                    cur_order_string += \" \"\n",
    "                    cur_order_string += str(product[3])\n",
    "                except:\n",
    "                    cur_order_string = str(product[3])\n",
    "        else:\n",
    "            cur_order_string = \"\"\n",
    "\n",
    "        # Turn string into vector\n",
    "        cur_order_x_temp = doc2vec_model.infer_vector(cur_order_string.split())\n",
    "\n",
    "        # Expand vectors to include empty timestep dimension\n",
    "        cur_order_x_temp = np.expand_dims(cur_order_x_temp, axis=0)\n",
    "\n",
    "        # cur_order_x_temp is the vector of this time step's basket. \n",
    "        # add it to the tensor for cur_order_x_train\n",
    "        # Notice, cur_order_x_temp is added on left, we are going backwards in timesteps\n",
    "        try:\n",
    "            cur_order_x_train = np.append(cur_order_x_temp, cur_order_x_train, axis=0)\n",
    "        except:\n",
    "            cur_order_x_train = cur_order_x_temp\n",
    "            \n",
    "    # Expand to 3 dimensions\n",
    "    cur_order_x_train = np.expand_dims(cur_order_x_train, axis=0)\n",
    "    \n",
    "    # Make Prediction\n",
    "    prediction = LSTM_model_predict.predict(cur_order_x_train)\n",
    "    \n",
    "    # Find closest basket \n",
    "    #closest_basket = doc2vec_model.docvecs.most_similar([prediction], topn=1)\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81609, 4)\n",
      "(1224500, 4)\n"
     ]
    }
   ],
   "source": [
    "print(y_validation.shape)\n",
    "print(x_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "cur_user = y_validation[i][0]\n",
    "cur_user_order_num = y_validation[i][3]\n",
    "cur_user_prior_orders = x_validation[np.where(x_validation[:,0] == cur_user)]\n",
    "cur_user_input = makePrediction(cur_user_prior_orders, cur_user_order_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1720460, 0.7618535757064819)]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(cur_user_input.flatten())\n",
    "doc2vec_model.docvecs.most_similar([cur_user_input.flatten()], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38557 20995 13176 47766 37646 46969 21137 21174 260 24184 16759 46049 1468 40706 22035\n"
     ]
    }
   ],
   "source": [
    "print(order_dict[1720460])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[182389    170  18394      7]\n",
      " [182389    170  37766      7]\n",
      " [182389    170  13176      7]\n",
      " [182389    170   6236      7]\n",
      " [182389    170   5077      7]\n",
      " [182389    170   8153      7]\n",
      " [182389    170  43772      7]\n",
      " [182389    170  25591      7]\n",
      " [182389    170  34582      7]\n",
      " [182389    170  49593      7]\n",
      " [182389    170  15093      7]\n",
      " [182389    170  43841      7]\n",
      " [182389    170  21137      7]\n",
      " [182389    170  40354      7]\n",
      " [182389    170  17794      7]\n",
      " [182389    170  11182      7]\n",
      " [182389    170  39190      7]\n",
      " [ 77529    473  20082      7]\n",
      " [ 77529    473  24852      7]\n",
      " [ 77529    473  47144      7]\n",
      " [ 77529    473  36441      7]\n",
      " [ 77529    473  12206      7]\n",
      " [ 77529    473   4034      7]\n",
      " [ 77529    473  30573      7]\n",
      " [ 77529    473  42404      7]\n",
      " [ 27650    774  47482     25]\n",
      " [ 27650    774  43335     25]\n",
      " [ 27650    774  16108     25]\n",
      " [ 10125   1275   6046      5]\n",
      " [ 10125   1275  48679      5]]\n"
     ]
    }
   ],
   "source": [
    "print(y_validation[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "66px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
