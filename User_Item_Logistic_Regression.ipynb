{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# User/Item Logistic Regression\n",
    "\n",
    "How about a ton of features for a given user/item combo? I bet we can get better than 0.0176.\n",
    "\n",
    "I'll use sklearn.linear_model.LogisticRegression - http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "For starters, I'll use the options from Assignment 3: \n",
    "\n",
    "* multi_class=\"multinomial\"−multi_class=\"multinomial\"− we want to build softmax classifier (there are other ways of dealing with multiclass setting for Logistic Regression)\n",
    "* C=106−C=106−  for now we don't want to use regularization;  CC  is the inverse regularization constant which is  *C=1λC=1λ ; thus we should make  CC  big to turn of regulazrization\n",
    "* solver=sag−solver=sag−  optimization algorithm to use; Stochastic Average Gradient. Stochastic Gradient Descent method gitters massively. This is due to the not very good approximation of gradient (only by one example). To neglect this error one can simply average gradient across last few steps; that is exectly what  sagsag  does\n",
    "* n_iter=15−n_iter=15−  the number of passes over the training data (aka epochs)\n",
    "\n",
    "** Pseudocode **\n",
    "\n",
    "time_of_day\n",
    "day_of_week\n",
    "total_previous_orders\n",
    "\n",
    "-- Item specific features -- \n",
    "total_previous_buys_item\n",
    "time_since_last_buy_item\n",
    "last_buy_time_of_day_item\n",
    "last_buy_day_of_week_item\n",
    "average_duration_between_buys_user_item\n",
    "average_duration_between_buys_population_item \n",
    "rebuy_percentage_item - Amongst all people purchasing this item before, what percentage rebuy it? \n",
    "\n",
    "\n",
    "-- Aisle specific features --\n",
    "total_previous_buys_aisle\n",
    "time_since_last_buy_aisle\n",
    "last_buy_time_of_day_aisle\n",
    "last_buy_day_of_week_aisle\n",
    "average_duration_between_buys_user_aisle\n",
    "average_duration_between_buys_population_aisle\n",
    "rebuy_percentage_aisle\n",
    "\n",
    "-- Department specific features -- \n",
    "total_previous_buys_dept\n",
    "time_since_last_buy_dept\n",
    "last_buy_time_of_day_dept\n",
    "last_buy_day_of_week_dept\n",
    "average_duration_between_buys_user_dept\n",
    "average_duration_between_buys_population_dept\n",
    "rebuy_percentage_dept\n",
    "\n",
    "1. Start with order_num = 1, collect every item, grab dow, order time, etc. , tie to aisle and dept. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3 \n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Rebuys\n",
    "\n",
    "For each transaction in a user's purchase history, let's get what products were purchased and track them. As a result, we should get the following features:\n",
    "\n",
    "* total_previous_buys\n",
    "* time_since_last_buy\n",
    "* last_buy_day_of_week\n",
    "* last_buy_hour_of_Day\n",
    "* last order number\n",
    "* history_size\n",
    "\n",
    "Start with the first transaction (which every guest has) to initialize, then loop through each subsequent purchase and update. \n",
    "\n",
    "For fun, I'll keep a copy of the status as we pass through, since it seems like it will generate great training data for later. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Buys using first transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "database disk image is malformed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-517575bcbe78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DROP TABLE IF EXISTS user_item_history_order;\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Initialize first table using first orders.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: database disk image is malformed"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"instacart.db\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"DROP TABLE IF EXISTS user_item_history_order;\")\n",
    "\n",
    "# Initialize first table using first orders. \n",
    "cur.execute(\"CREATE TABLE user_item_history_order AS \"\n",
    "    \"SELECT A.user_id as user_id \"\n",
    "    \", B.product_id as product_id \"\n",
    "    \", 1 as total_previous_buys_item \"\n",
    "    \", 0 as time_since_last_buy_item \"\n",
    "    \", A.order_dow as last_buy_day_of_week_item \"\n",
    "    \", A.order_hour_of_day as last_buy_time_of_day_item \"\n",
    "    \", 1 as last_order_number \"\n",
    "    \", 1 as orders_in_history \"\n",
    "    \"FROM orders A \"\n",
    "    \" INNER JOIN products_prior B \"\n",
    "    \"  ON A.order_id = B.order_id \"\n",
    "    \"WHERE A.order_number = 1 \"\n",
    "    \"AND A.eval_set = 'prior';\")\n",
    "\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate through order_number for items\n",
    "\n",
    "For each subsequent order k = 2 through 100, there's four options\n",
    "\n",
    "1. **The user did not make a subsequent order** - there may be an order in train or test, but no prior orders remain for this user_id. Carve them out to save processing time\n",
    "2. **The user did not repurchase a given item in this new order** - This means the kth order did not rebuy the item. Most of the stats do not change, but time since last order certainly increases \n",
    "3. **Previously purchased item was rebought** - Increase the order count and reset many of the columns\n",
    "4. **The user purchased a new item not previously bought** - Do actions from the initialize step\n",
    "\n",
    "After that, union together options 2 + 3 + 4 to finish\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"instacart.db\")\n",
    "cur = conn.cursor()\n",
    "    \n",
    "    \n",
    "# Create holding table\n",
    "cur.execute(\"DROP TABLE IF EXISTS user_item_history_order_done\")\n",
    "cur.execute(\"CREATE TABLE user_item_history_order_done (\"\n",
    "            \"user_id integer, \"\n",
    "            \"product_id integer, \"\n",
    "            \"total_previous_buys_item integer, \"\n",
    "            \"time_since_last_buy_item integer, \"\n",
    "            \"last_buy_day_of_week_item integer, \"\n",
    "            \"last_buy_time_of_day_item integer, \"\n",
    "            \"last_order_number integer, \"\n",
    "            \"orders_in_history integer);\")\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "# For each order_num:\n",
    "for order_num in range(2, 101):\n",
    "    conn = sqlite3.connect(\"instacart.db\")\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    # Print progress\n",
    "    print(\"Starting on order \" + str(order_num))\n",
    "    \n",
    "    prev_order_num = order_num - 1\n",
    "    \n",
    "    ### \n",
    "    # 0.a) Grab the orders/products for this order_num\n",
    "    ### \n",
    "    \n",
    "    cur.execute(\"DROP TABLE IF EXISTS products_for_this_order;\")\n",
    "    cur.execute(\"CREATE TABLE products_for_this_order AS \"\n",
    "                \"SELECT A.order_id as order_id \"\n",
    "                \" , A.user_id as user_id \"\n",
    "                \" , A.order_dow as order_dow \"\n",
    "                \" , A.order_hour_of_day as order_hour_of_day \"\n",
    "                \" , A.days_since_prior_order as days_since_prior_order \"\n",
    "                \" , A.order_number as order_number \"\n",
    "                \" , B.product_id \"\n",
    "                \"FROM orders A \"\n",
    "                \" INNER JOIN products_prior B \"\n",
    "                \" ON A.order_id = B.order_id \"\n",
    "                \"WHERE A.order_number = ? \"\n",
    "                \" AND A.eval_set = 'prior';\", (order_num,))    \n",
    "        \n",
    "    print(\"Grab products done\")\n",
    "       \n",
    "    ###\n",
    "    # 0.b) Grab the orders/products from last round\n",
    "    ###\n",
    "    cur.execute(\"DROP TABLE IF EXISTS history_for_this_order;\")\n",
    "    cur.execute(\"CREATE TABLE history_for_this_order AS \"\n",
    "                \"SELECT * \"\n",
    "                \"FROM user_item_history_order \"\n",
    "                \"WHERE orders_in_history = ?;\", (prev_order_num,))\n",
    "                \n",
    "    print(\"Grab history done\")\n",
    "                \n",
    "    ###\n",
    "    # 1) No purchase for this user\n",
    "    ###\n",
    "    \n",
    "    ## Copy results from iteration table to final done table\n",
    "    cur.execute(\"INSERT INTO user_item_history_order_done \"\n",
    "                \"SELECT A.* \"\n",
    "                \"FROM history_for_this_order A \"\n",
    "                \" LEFT OUTER JOIN orders B \"\n",
    "                \"  ON A.user_id = B.user_id \"\n",
    "                \"  AND B.order_number = ? \"\n",
    "                \"WHERE B.order_id IS NULL;\", (order_num,))\n",
    " \n",
    "    print(\"No more purchases done\")\n",
    "    \n",
    "    ###\n",
    "    # 2) Items not repurchased this order\n",
    "    ###\n",
    "    \n",
    "    ## History (Z) left joined to products A, looking for product on A to be empty\n",
    "    ##  -> This says the previously purchased product on table Z was not purchased this order \n",
    "    \n",
    "    cur.execute(\"DROP TABLE IF EXISTS user_item_history_order_2a;\")\n",
    "    cur.execute(\"CREATE TABLE user_item_history_order_2a AS \" \n",
    "                \"SELECT Z.user_id as user_id \"\n",
    "                \" ,Z.product_id as product_id \"\n",
    "                \" ,Z.total_previous_buys_item as total_previous_buys_item \"\n",
    "                \" ,Z.time_since_last_buy_item as time_since_last_buy_item \"\n",
    "                \" ,Z.last_buy_day_of_week_item as last_buy_day_of_week_item \"\n",
    "                \" ,Z.last_buy_time_of_day_item as last_buy_time_of_day_item \"\n",
    "                \" ,Z.last_order_number as last_order_number \"\n",
    "                \" ,Z.orders_in_history + 1 as orders_in_history \"\n",
    "                \"FROM history_for_this_order Z \"\n",
    "                \" LEFT OUTER JOIN products_for_this_order A \"\n",
    "                \"  ON Z.user_id = A.user_id \"\n",
    "                \"  AND Z.product_id = A.product_id \"\n",
    "                \"WHERE A.product_id IS NULL;\")\n",
    "    \n",
    "    ## None of the items in _2a were purchased, but an order happened. Join to\n",
    "    # the order and get the days since last order. \n",
    "    \n",
    "    cur.execute(\"DROP TABLE IF EXISTS user_item_history_order_2b;\")\n",
    "    cur.execute(\"CREATE TABLE user_item_history_order_2b AS \" \n",
    "                \"SELECT Z.user_id as user_id \"\n",
    "                \" ,Z.product_id as product_id \"\n",
    "                \" ,Z.total_previous_buys_item as total_previous_buys_item \"\n",
    "                \" ,(Z.time_since_last_buy_item + A.days_since_prior_order) as time_since_last_buy_item \"\n",
    "                \" ,Z.last_buy_day_of_week_item as last_buy_day_of_week_item \"\n",
    "                \" ,Z.last_buy_time_of_day_item as last_buy_time_of_day_item \"\n",
    "                \" ,Z.last_order_number as last_order_number \"\n",
    "                \" ,Z.orders_in_history as orders_in_history \"\n",
    "                \"FROM user_item_history_order_2a Z \"\n",
    "                \" INNER JOIN orders A \"\n",
    "                \"  ON Z.user_id = A.user_id \"\n",
    "                \"  AND A.order_number = ?;\", (order_num,))\n",
    "    \n",
    "    print(\"No repurchase done\")\n",
    "\n",
    "    ###\n",
    "    # 3) Items that were repurchased this order\n",
    "    ###\n",
    "    \n",
    "    ## History inner joined to products, only report on matches.\n",
    "\n",
    "    \n",
    "    cur.execute(\"DROP TABLE IF EXISTS user_item_history_order_3;\")\n",
    "    cur.execute(\"CREATE TABLE user_item_history_order_3 AS \" \n",
    "                \"SELECT Z.user_id as user_id \"\n",
    "                \" ,Z.product_id as product_id \"\n",
    "                \" ,Z.total_previous_buys_item + 1 as total_previous_buys_item \"\n",
    "                \" ,0 as time_since_last_buy_item \"\n",
    "                \" ,A.order_dow as last_buy_day_of_week_item \"\n",
    "                \" ,A.order_hour_of_day as last_buy_time_of_day_item \"\n",
    "                \" ,A.order_number as last_order_number \"\n",
    "                \" ,Z.orders_in_history + 1 as orders_in_history \"\n",
    "                \"FROM history_for_this_order Z \"\n",
    "                \" INNER JOIN products_for_this_order A \"\n",
    "                \"  ON Z.user_id = A.user_id \"\n",
    "                \"  AND Z.product_id = A.product_id;\")\n",
    "    \n",
    "    print(\"Repurchase Done\")\n",
    "    \n",
    "    ###\n",
    "    # 4) New items not previous purchased\n",
    "    ###\n",
    "    \n",
    "    ## History is in right position now, looking for products in history to be null\n",
    "\n",
    "    \n",
    "    cur.execute(\"DROP TABLE IF EXISTS user_item_history_order_4;\")\n",
    "    cur.execute(\"CREATE TABLE user_item_history_order_4 AS \" \n",
    "                \"SELECT A.user_id as user_id \"\n",
    "                \" ,A.product_id as product_id \"\n",
    "                \" ,1 as total_previous_buys_item \"\n",
    "                \" ,0 as time_since_last_buy_item \"\n",
    "                \" ,A.order_dow as last_buy_day_of_week_item \"\n",
    "                \" ,A.order_hour_of_day as last_buy_time_of_day_item \"\n",
    "                \" ,A.order_number as last_order_number \"\n",
    "                \" ,A.order_number as orders_in_history \"\n",
    "                \"FROM products_for_this_order A \"\n",
    "                \" LEFT OUTER JOIN history_for_this_order Z \"\n",
    "                \"  ON A.user_id = Z.user_id \"\n",
    "                \"  AND A.product_id = Z.product_id \"\n",
    "                \"WHERE Z.product_id IS NULL;\")\n",
    "    \n",
    "    \n",
    "    print(\"New purchases done\")\n",
    "    \n",
    "    ###\n",
    "    # Union together to finish order_num\n",
    "    ###\n",
    "    \n",
    "    cur.execute(\"INSERT INTO user_item_history_order \"\n",
    "                \"SELECT * FROM user_item_history_order_2b;\")\n",
    "    cur.execute(\"INSERT INTO user_item_history_order \"\n",
    "                \"SELECT * FROM user_item_history_order_3;\")\n",
    "    cur.execute(\"INSERT INTO user_item_history_order \"\n",
    "                \"SELECT * FROM user_item_history_order_4;\")\n",
    "    \n",
    "    print(\"Union Done\")\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"instacart.db\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "###\n",
    "# One last insert for users with 100 orders:\n",
    "###\n",
    "\n",
    "## Copy results from iteration table to final done table\n",
    "cur.execute(\"INSERT INTO user_item_history_order_done \"\n",
    "            \"SELECT A.* \"\n",
    "            \"FROM history_for_this_order A \"\n",
    "            \" LEFT OUTER JOIN orders B \"\n",
    "            \"  ON A.user_id = B.user_id \"\n",
    "            \"  AND B.order_number = 101 \"\n",
    "            \"WHERE B.order_id IS NULL;\")\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now got a table of every product purchased by every user, how long it's been, etc. Now I want to know purchase cycle info. \n",
    "\n",
    "Let's talk this out. Say user_id = 1, product_id = 196. \n",
    "\n",
    "History looks like this: \n",
    "\n",
    "|user_id|product_id|total_previous_buys|time_since_last_buy_item|last_buy_day_of_week_item|last_buy_time_of_day_item|last_order_number|orders_in_history\n",
    "|-------------------\n",
    "|1|196|1|0|2|8|1|1\n",
    "|1|196|2|0|3|7|2|2\n",
    "|1|196|3|0|3|12|3|3\n",
    "|1|196|4|0|4|7|4|4\n",
    "|1|196|5|0|4|15|5|5\n",
    "|1|196|6|0|2|7|6|6\n",
    "|1|196|7|0|1|9|7|7\n",
    "|1|196|8|0|1|14|8|8\n",
    "|1|196|9|0|1|16|9|9\n",
    "|1|196|10|0|4|8|10|10\n",
    "|1|196|10|14|4|8|10|11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we can calculate purchase cycle and then aggregate for each user/item, then across all users for each item.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_item_purchases Done\n",
      "user_item_first_purchase Done\n",
      "user_item_rebuy Done\n",
      "user_item_rebuy_duration Done\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"instacart.db\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "###\n",
    "# Calculate rebuy for each item/user\n",
    "###\n",
    "\n",
    "# Filter order history on only purchases: \n",
    "cur.execute(\"CREATE TABLE user_item_purchases AS \"\n",
    "            \"SELECT * \"\n",
    "            \"FROM user_item_history_order \"\n",
    "            \"WHERE last_order_number = orders_in_history;\")\n",
    "\n",
    "print(\"user_item_purchases Done\")\n",
    "\n",
    "# Calculate first order for each item to remove\n",
    "cur.execute(\"CREATE TABLE user_item_first_purchase AS \"\n",
    "            \"SELECT user_id, product_id, MIN(last_order_number) as first_order_number \"\n",
    "            \"FROM user_item_purchases \"\n",
    "            \"GROUP BY user_id, product_id;\")\n",
    "\n",
    "print(\"user_item_first_purchase Done\")\n",
    "\n",
    "# Remove first order to only reflect rebuys\n",
    "cur.execute(\"CREATE TABLE user_item_rebuy AS \"\n",
    "            \"SELECT A.* \"\n",
    "            \"FROM user_item_purchases A \"\n",
    "            \"  LEFT OUTER JOIN user_item_first_purchase B \"\n",
    "            \"  ON A.user_id = B.user_id \"\n",
    "            \"  AND A.product_id = B.product_id \"\n",
    "            \"  AND A.last_order_number = B.first_order_number \"\n",
    "            \"WHERE B.first_order_number is NULL;\")\n",
    "\n",
    "print(\"user_item_rebuy Done\")\n",
    "\n",
    "# Combine with order stats to get full time since last purchase\n",
    "# *** You may be wondering why this wasn't calcualted before!\n",
    "# *** user_item_history_order was designed so that it takes in\n",
    "# *** the next order as part of the time-since-last-buy, \n",
    "# *** since that is what the model will take in as input\n",
    "cur.execute(\"CREATE TABLE user_item_rebuy_duration AS \"\n",
    "            \"SELECT A.user_id, A.product_id, B.order_number, \"\n",
    "            \" A.total_previous_buys_item, \"\n",
    "            \" A.time_since_last_buy_item + B.days_since_prior_order \"\n",
    "            \"  as rebuy_duration, \"\n",
    "            \" B.order_dow, \"\n",
    "            \" B.order_hour_of_day \"\n",
    "            \"FROM user_item_rebuy A \"\n",
    "            \" INNER JOIN orders B \"\n",
    "            \" ON A.user_id = B.user_id \"\n",
    "            \" AND A.last_order_number = B.order_number;\")\n",
    "            \n",
    "\n",
    "    \n",
    "print(\"user_item_rebuy_duration Done\")\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with user_item_rebuy_duration, I can get a sense of average time to rebuy for each item/user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"instacart.db\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Calculate the average rebuy per item, etc.\n",
    "cur.execute(\"CREATE TABLE user_item_averages AS \"\n",
    "            \"SELECT user_id, product_id, \"\n",
    "            \" AVG(rebuy_duration) as average_rebuy_duration, \"\n",
    "            \" AVG(order_dow) as average_rebuy_dow, \"\n",
    "            \" AVG(order_hour_of_day) as average_rebuy_hod \"\n",
    "            \"FROM user_item_rebuy_duration \"\n",
    "            \"GROUP BY user_id, product_id;\")\n",
    "            \n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Logistic Model With Just User Features\n",
    "\n",
    "Okay, that's lots of features for each user/product. Let's see how well it predicts! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"instacart.db\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Get one row per user and product\n",
    "cur.execute(\"DROP TABLE IF EXISTS features_1;\")\n",
    "cur.execute(\"CREATE TABLE features_1 AS \"\n",
    "            \"SELECT A.*, \"\n",
    "            \"COALESCE(B.average_rebuy_duration, time_since_last_buy_item) as average_rebuy_duration, \"\n",
    "            \"COALESCE(B.average_rebuy_dow, last_buy_day_of_week_item) as average_rebuy_dow, \"\n",
    "            \"COALESCE(B.average_rebuy_hod, last_buy_time_of_day_item) as average_rebuy_hod \"\n",
    "            \"FROM user_item_history_order_done A \"\n",
    "            \" LEFT OUTER JOIN user_item_averages B \"\n",
    "            \" ON A.user_id = B.user_id \"\n",
    "            \"  AND A.product_id = B.product_id;\")\n",
    "\n",
    "\n",
    "# Combine with features about current order\n",
    "cur.execute(\"DROP TABLE IF EXISTS features_1_b;\")\n",
    "cur.execute(\"CREATE TABLE features_1_b AS \"\n",
    "            \"SELECT A.user_id, \"\n",
    "            \" A.product_id, \"\n",
    "            \" A.total_previous_buys_item, \"\n",
    "            \" A.time_since_last_buy_item + B.days_since_prior_order as time_since_last_buy_item, \"\n",
    "            \" A.last_buy_day_of_week_item, \"\n",
    "            \" A.last_buy_Time_of_day_item, \"\n",
    "            \" A.last_order_number, \"\n",
    "            \" A.orders_in_history, \"\n",
    "            \" A.average_rebuy_duration, \"\n",
    "            \" A.average_rebuy_dow, \"\n",
    "            \" A.average_rebuy_hod, \"\n",
    "            \" B.order_id, \"\n",
    "            \" B.order_number, \"\n",
    "            \" B.order_dow, \"\n",
    "            \" B.order_hour_of_day, \"\n",
    "            \" B.days_since_prior_order \"\n",
    "            \"FROM features_1 A \"\n",
    "            \" INNER JOIN orders B \"\n",
    "            \" ON A.user_id = B.user_id \"\n",
    "            \"WHERE B.eval_set = 'train';\")\n",
    "\n",
    "# Append training and validation results \n",
    "cur.execute(\"DROP TABLE IF EXISTS features_1_c;\")\n",
    "cur.execute(\"CREATE TABLE features_1_c AS \"\n",
    "            \"SELECT A.*, \"\n",
    "            \" CASE WHEN B.product_id is NULL THEN 0 ELSE 1 END AS reorder \"\n",
    "            \"FROM features_1_b A \"\n",
    "            \" LEFT OUTER JOIN products_train B \"\n",
    "            \" ON A.order_id = B.order_id \"\n",
    "            \"  AND A.product_id = B.product_id;\")\n",
    "\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0iteration, score: 0.904487822741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# It's a lot of data and it kills the kernal, so let's operate on 1/10th at a time\n",
    "\n",
    "model_lr_sklearn = LogisticRegression(multi_class=\"ovr\", C=1e6, solver=\"sag\", max_iter=100, warm_start=True)\n",
    "\n",
    "for i in range(1):\n",
    "    conn = sqlite3.connect(\"instacart.db\")\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT * FROM features_1_c WHERE order_id % 10 = \" + str(i) + \";\")\n",
    "\n",
    "    thefeatures = np.array(cur.fetchall())\n",
    "\n",
    "    # Split feature data into features to train on and the evaluation\n",
    "    x_train = thefeatures[:,[2,3,4,5,6,7,8,9,10,12,13,14,15]]\n",
    "    y_train = thefeatures[:,[16]]\n",
    "    y_train_flat = y_train.flatten()\n",
    "\n",
    "    model_lr_sklearn.fit(x_train, y_train_flat)\n",
    "    \n",
    "    print(str(i) + \"iteration, score: \" + str(model_lr_sklearn.score(x_train, y_train_flat)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Score on validation set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"instacart.db\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "user_item_logistic = dict()\n",
    "\n",
    "# validation set is orders ending with 7/8/9.\n",
    "for i in [7, 8, 9]:\n",
    "    print(i)\n",
    "    # Get data for predictions\n",
    "    conn = sqlite3.connect(\"instacart.db\")\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT * FROM features_1_c WHERE order_id % 10 = \" + str(i) + \";\")\n",
    "    validation = cur.fetchall()\n",
    "    validation_array = np.array(validation)\n",
    "    conn.close()\n",
    "    \n",
    "    # Put into array: \n",
    "    x_pred = validation_array[:,[2,3,4,5,6,7,8,9,10,12,13,14,15]]\n",
    "    predictions = model_lr_sklearn.predict(x_pred)\n",
    "    \n",
    "    # Get order and products\n",
    "    x_lookup = validation_array[:, [1, 11]]\n",
    "    \n",
    "    x_assemble = np.column_stack((x_lookup, predictions))\n",
    "    \n",
    "    # Assert: x_assemble column 0 == product id; 1 == order id; 2 == reorder prediction\n",
    "    \n",
    "    # For each row: \n",
    "    for i in range(x_assemble.shape[0]):\n",
    "        # if it is a new order number, create a set\n",
    "        if int(x_assemble[i,1]) not in user_item_logistic:\n",
    "            user_item_logistic[int(x_assemble[i,1])] = set()\n",
    "        if x_assemble[i,2] == 1:\n",
    "            user_item_logistic[int(x_assemble[i,1])].add(str(int(x_assemble[i,0])))\n",
    "    \n",
    "# Add \"None\" to orders with no items\n",
    "for y in [x for x in user_item_logistic.keys() if len(user_item_logistic[x]) == 0]:\n",
    "    user_item_logistic[y].add(\"None\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "True Positives:  16982\n",
      "False Positives: 39880\n",
      "False Negatives: 237140\n",
      "Precision:       0.2986528788997925\n",
      "Recall:          0.06682617010727131\n",
      "----------------------------\n",
      "F1: 0.10921462197412084\n"
     ]
    }
   ],
   "source": [
    "# Grab f1 score:\n",
    "%run F1_Score.ipynb   \n",
    "\n",
    "# grab actual results: \n",
    "%run Load_actual_results.ipynb\n",
    "\n",
    "# Score: \n",
    "user_item_logistic_results = f1(user_item_logistic, actual_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Model        F1  True_Positives  False_Positives  \\\n",
      "0         Dummy Model  0.017609            2586            37002   \n",
      "1       Naive_Reorder  0.004044             887           183617   \n",
      "2  User_Item_Logistic  0.111259           17314            39802   \n",
      "\n",
      "   False_Negatives  \n",
      "0           251536  \n",
      "1           253235  \n",
      "2           236808  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Write to results table\n",
    "con = sqlite3.connect(\"instacart.db\")\n",
    "cur = con.cursor()\n",
    "\n",
    "# Insert into model results\n",
    "cur.execute(\"INSERT INTO model_results (Model, F1, True_Positives, \"\n",
    "            \"False_Positives, False_Negatives) VALUES (?, ?, ?, ?, ?);\",\n",
    "            list((\"User_Item_Logistic\",) + user_item_logistic_results ) )\n",
    "\n",
    "# Print contents of model_results\n",
    "print(pd.read_sql_query(\"SELECT * FROM model_Results;\", con))\n",
    "\n",
    "con.commit()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retry prediction with lower probability threshold \n",
    "\n",
    "predict simply guesses 0 or 1, but given the false negatives, perhaps I should be more liberal.\n",
    "\n",
    "user_item_logistic_lower set at rebuy probability at > .25\n",
    "user_item_logistic_even_lower set at rebuy probability at > .15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "8\n",
      "9\n",
      "===================\n",
      "= Cuttoff at 0.1\n",
      "True Positives:  203585\n",
      "False Positives: 838505\n",
      "False Negatives: 50537\n",
      "Precision:       0.1953622047999693\n",
      "Recall:          0.8011309528494188\n",
      "----------------------------\n",
      "F1: 0.3141229983984102\n",
      "===================\n",
      "= Cuttoff at 0.11\n",
      "True Positives:  197179\n",
      "False Positives: 761963\n",
      "False Negatives: 56943\n",
      "Precision:       0.205578527475598\n",
      "Recall:          0.7759225883630697\n",
      "----------------------------\n",
      "F1: 0.32503890332194807\n",
      "===================\n",
      "= Cuttoff at 0.12\n",
      "True Positives:  190169\n",
      "False Positives: 687948\n",
      "False Negatives: 63953\n",
      "Precision:       0.2165645352498585\n",
      "Recall:          0.7483374127387633\n",
      "----------------------------\n",
      "F1: 0.33591671016455005\n",
      "===================\n",
      "= Cuttoff at 0.13\n",
      "True Positives:  182207\n",
      "False Positives: 610907\n",
      "False Negatives: 71915\n",
      "Precision:       0.2297362043791939\n",
      "Recall:          0.7170060049897293\n",
      "----------------------------\n",
      "F1: 0.3479769603031217\n",
      "===================\n",
      "= Cuttoff at 0.14\n",
      "True Positives:  173447\n",
      "False Positives: 533977\n",
      "False Negatives: 80675\n",
      "Precision:       0.24518110779391142\n",
      "Recall:          0.6825343732537915\n",
      "----------------------------\n",
      "F1: 0.3607669315872563\n",
      "===================\n",
      "= Cuttoff at 0.15\n",
      "True Positives:  164911\n",
      "False Positives: 471635\n",
      "False Negatives: 89211\n",
      "Precision:       0.25907161462015316\n",
      "Recall:          0.6489442079001424\n",
      "----------------------------\n",
      "F1: 0.3703085773823692\n",
      "===================\n",
      "= Cuttoff at 0.16\n",
      "True Positives:  156225\n",
      "False Positives: 413391\n",
      "False Negatives: 97897\n",
      "Precision:       0.2742637145024016\n",
      "Recall:          0.6147637748797822\n",
      "----------------------------\n",
      "F1: 0.37930749825794124\n",
      "===================\n",
      "= Cuttoff at 0.17\n",
      "True Positives:  146683\n",
      "False Positives: 357126\n",
      "False Negatives: 107439\n",
      "Precision:       0.2911480342748939\n",
      "Recall:          0.5772148810413895\n",
      "----------------------------\n",
      "F1: 0.3870616190655878\n",
      "===================\n",
      "= Cuttoff at 0.18\n",
      "True Positives:  135867\n",
      "False Positives: 300641\n",
      "False Negatives: 118255\n",
      "Precision:       0.3112589001805236\n",
      "Recall:          0.5346526471537293\n",
      "----------------------------\n",
      "F1: 0.39345814690934366\n",
      "===================\n",
      "= Cuttoff at 0.19\n",
      "True Positives:  123604\n",
      "False Positives: 240414\n",
      "False Negatives: 130518\n",
      "Precision:       0.33955463740804026\n",
      "Recall:          0.48639629784119437\n",
      "----------------------------\n",
      "F1: 0.39992234768822593\n",
      "===================\n",
      "= Cuttoff at 0.2\n",
      "True Positives:  110054\n",
      "False Positives: 182078\n",
      "False Negatives: 144068\n",
      "Precision:       0.37672695904591075\n",
      "Recall:          0.4330754519482768\n",
      "----------------------------\n",
      "F1: 0.40294075649789296\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"instacart.db\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "x_assemble = dict()\n",
    "\n",
    "# validation set is orders ending with 7/8/9.\n",
    "for i in [7, 8, 9]:\n",
    "    print(i)\n",
    "    # Get data for predictions\n",
    "    conn = sqlite3.connect(\"instacart.db\")\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT * FROM features_1_c WHERE order_id % 10 = \" + str(i) + \";\")\n",
    "    validation = cur.fetchall()\n",
    "    validation_array = np.array(validation)\n",
    "    conn.close()\n",
    "\n",
    "    # Put into array: \n",
    "    x_pred = validation_array[:,[2,3,4,5,6,7,8,9,10,12,13,14,15]]\n",
    "    predictions = model_lr_sklearn.predict_proba(x_pred)\n",
    "\n",
    "    # Get order and products\n",
    "    x_lookup = validation_array[:, [1, 11]]\n",
    "\n",
    "    x_assemble[i] = np.column_stack((x_lookup, predictions))\n",
    "\n",
    "# Assert: x_assemble column 0 == product id; 1 == order id; 2 == reorder prediction\n",
    "\n",
    "x_assemble_all = np.vstack((x_assemble[7], x_assemble[8], x_assemble[9]))\n",
    "\n",
    "for j in [.1, .11, .12, .13, .14, .15, .16, .17, .18, .19, .2]:\n",
    "    user_item_logistic_lower = dict()\n",
    "    \n",
    "    # For each row: \n",
    "    for i in range(x_assemble_all.shape[0]):\n",
    "       # if it is a new order number, create a set\n",
    "        if int(x_assemble_all[i,1]) not in user_item_logistic_lower:\n",
    "            user_item_logistic_lower[int(x_assemble_all[i,1])] = set()\n",
    "        if x_assemble_all[i,3] > j:\n",
    "            user_item_logistic_lower[int(x_assemble_all[i,1])].add(str(int(x_assemble_all[i,0])))\n",
    "\n",
    "    # Add \"None\" to orders with no items\n",
    "    for y in [x for x in user_item_logistic_lower.keys() if len(user_item_logistic_lower[x]) == 0]:\n",
    "        user_item_logistic_lower[y].add(\"None\")\n",
    "\n",
    "    print(\"===================\")\n",
    "    print(\"= Cuttoff at \" + str(j))\n",
    "    # Score: \n",
    "    user_item_logistic_results = f1(user_item_logistic_lower, actual_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================\n",
      "= Cuttoff at 0.191\n",
      "True Positives:  122220\n",
      "False Positives: 234369\n",
      "False Negatives: 131902\n",
      "Precision:       0.34274753287398096\n",
      "Recall:          0.48095009483633844\n",
      "----------------------------\n",
      "F1: 0.4002547849965041\n",
      "===================\n",
      "= Cuttoff at 0.192\n",
      "True Positives:  120895\n",
      "False Positives: 228392\n",
      "False Negatives: 133227\n",
      "Precision:       0.34611938033765927\n",
      "Recall:          0.47573606378038896\n",
      "----------------------------\n",
      "F1: 0.4007066517072168\n",
      "===================\n",
      "= Cuttoff at 0.193\n",
      "True Positives:  119481\n",
      "False Positives: 222245\n",
      "False Negatives: 134641\n",
      "Precision:       0.34963976987410966\n",
      "Recall:          0.47017180724219076\n",
      "----------------------------\n",
      "F1: 0.4010452330124462\n",
      "===================\n",
      "= Cuttoff at 0.194\n",
      "True Positives:  118087\n",
      "False Positives: 215933\n",
      "False Negatives: 136035\n",
      "Precision:       0.35353272259146157\n",
      "Recall:          0.4646862530595541\n",
      "----------------------------\n",
      "F1: 0.40155948733469127\n",
      "===================\n",
      "= Cuttoff at 0.195\n",
      "True Positives:  116714\n",
      "False Positives: 210029\n",
      "False Negatives: 137408\n",
      "Precision:       0.35720428593726566\n",
      "Recall:          0.459283336350257\n",
      "----------------------------\n",
      "F1: 0.40186273919068977\n",
      "===================\n",
      "= Cuttoff at 0.196\n",
      "True Positives:  115393\n",
      "False Positives: 204310\n",
      "False Negatives: 138729\n",
      "Precision:       0.3609381206932684\n",
      "Recall:          0.45408504576541975\n",
      "----------------------------\n",
      "F1: 0.40218882063346834\n",
      "===================\n",
      "= Cuttoff at 0.197\n",
      "True Positives:  114041\n",
      "False Positives: 198459\n",
      "False Negatives: 140081\n",
      "Precision:       0.3649312\n",
      "Recall:          0.44876476652946223\n",
      "----------------------------\n",
      "F1: 0.4025293758449195\n",
      "===================\n",
      "= Cuttoff at 0.198\n",
      "True Positives:  112733\n",
      "False Positives: 192982\n",
      "False Negatives: 141389\n",
      "Precision:       0.36875194216835944\n",
      "Recall:          0.44361763247574\n",
      "----------------------------\n",
      "F1: 0.40273508181845785\n",
      "===================\n",
      "= Cuttoff at 0.199\n",
      "True Positives:  111387\n",
      "False Positives: 187526\n",
      "False Negatives: 142735\n",
      "Precision:       0.3726401996567563\n",
      "Recall:          0.4383209639464509\n",
      "----------------------------\n",
      "F1: 0.4028207979603461\n",
      "===================\n",
      "= Cuttoff at 0.2\n",
      "True Positives:  110054\n",
      "False Positives: 182078\n",
      "False Negatives: 144068\n",
      "Precision:       0.37672695904591075\n",
      "Recall:          0.4330754519482768\n",
      "----------------------------\n",
      "F1: 0.40294075649789296\n",
      "===================\n",
      "= Cuttoff at 0.201\n",
      "True Positives:  108784\n",
      "False Positives: 177124\n",
      "False Negatives: 145338\n",
      "Precision:       0.38048603047134044\n",
      "Recall:          0.4280778523701214\n",
      "----------------------------\n",
      "F1: 0.4028813214080699\n",
      "===================\n",
      "= Cuttoff at 0.202\n",
      "True Positives:  107526\n",
      "False Positives: 172371\n",
      "False Negatives: 146596\n",
      "Precision:       0.3841627455814103\n",
      "Recall:          0.42312747420530294\n",
      "----------------------------\n",
      "F1: 0.4027047726766276\n",
      "===================\n",
      "= Cuttoff at 0.203\n",
      "True Positives:  106281\n",
      "False Positives: 167875\n",
      "False Negatives: 147841\n",
      "Precision:       0.38766614628167906\n",
      "Recall:          0.41822825257159946\n",
      "----------------------------\n",
      "F1: 0.402367692767823\n",
      "===================\n",
      "= Cuttoff at 0.204\n",
      "True Positives:  105128\n",
      "False Positives: 163444\n",
      "False Negatives: 148994\n",
      "Precision:       0.3914332097165751\n",
      "Recall:          0.41369106177347886\n",
      "----------------------------\n",
      "F1: 0.40225447393694974\n",
      "===================\n",
      "= Cuttoff at 0.205\n",
      "True Positives:  103894\n",
      "False Positives: 159317\n",
      "False Negatives: 150228\n",
      "Precision:       0.3947175459992174\n",
      "Recall:          0.4088351264353342\n",
      "----------------------------\n",
      "F1: 0.4016523206522684\n",
      "===================\n",
      "= Cuttoff at 0.206\n",
      "True Positives:  102834\n",
      "False Positives: 155520\n",
      "False Negatives: 151288\n",
      "Precision:       0.39803525395387723\n",
      "Recall:          0.4046639015905746\n",
      "----------------------------\n",
      "F1: 0.40132220825950876\n",
      "===================\n",
      "= Cuttoff at 0.207\n",
      "True Positives:  101743\n",
      "False Positives: 152014\n",
      "False Negatives: 152379\n",
      "Precision:       0.4009465748728114\n",
      "Recall:          0.40037068809469467\n",
      "----------------------------\n",
      "F1: 0.4006584245460041\n"
     ]
    }
   ],
   "source": [
    "for j in [.191, .192, .193, .194, .195, .196, .197, .198, .199, .2, .201, .202, .203, .204, .205, .206, .207]:\n",
    "    user_item_logistic_lower = dict()\n",
    "    \n",
    "    # For each row: \n",
    "    for i in range(x_assemble_all.shape[0]):\n",
    "       # if it is a new order number, create a set\n",
    "        if int(x_assemble_all[i,1]) not in user_item_logistic_lower:\n",
    "            user_item_logistic_lower[int(x_assemble_all[i,1])] = set()\n",
    "        if x_assemble_all[i,3] > j:\n",
    "            user_item_logistic_lower[int(x_assemble_all[i,1])].add(str(int(x_assemble_all[i,0])))\n",
    "\n",
    "    # Add \"None\" to orders with no items\n",
    "    for y in [x for x in user_item_logistic_lower.keys() if len(user_item_logistic_lower[x]) == 0]:\n",
    "        user_item_logistic_lower[y].add(\"None\")\n",
    "\n",
    "    print(\"===================\")\n",
    "    print(\"= Cuttoff at \" + str(j))\n",
    "    # Score: \n",
    "    user_item_logistic_results = f1(user_item_logistic_lower, actual_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "True Positives:  203585\n",
      "False Positives: 838505\n",
      "False Negatives: 50537\n",
      "Precision:       0.1953622047999693\n",
      "Recall:          0.8011309528494188\n",
      "----------------------------\n",
      "F1: 0.3141229983984102\n"
     ]
    }
   ],
   "source": [
    "# Grab f1 score:\n",
    "%run F1_Score.ipynb   \n",
    "\n",
    "# grab actual results: \n",
    "%run Load_actual_results.ipynb\n",
    "\n",
    "# Score: \n",
    "user_item_logistic_results = f1(user_item_logistic_lower, actual_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Model        F1  True_Positives  False_Positives  \\\n",
      "0                    Dummy Model  0.017609            2586            37002   \n",
      "1                  Naive_Reorder  0.004044             887           183617   \n",
      "2             User_Item_Logistic  0.111259           17314            39802   \n",
      "3       User_Item_Logistic_Lower  0.332571           66918            81388   \n",
      "4  User_Item_Logistic_Even_Lower  0.370396          165545           474213   \n",
      "\n",
      "   False_Negatives  \n",
      "0           251536  \n",
      "1           253235  \n",
      "2           236808  \n",
      "3           187204  \n",
      "4            88577  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Write to results table\n",
    "con = sqlite3.connect(\"instacart.db\")\n",
    "cur = con.cursor()\n",
    "\n",
    "# Insert into model results\n",
    "cur.execute(\"INSERT INTO model_results (Model, F1, True_Positives, \"\n",
    "            \"False_Positives, False_Negatives) VALUES (?, ?, ?, ?, ?);\",\n",
    "            list((\"User_Item_Logistic_Even_Lower\",) + user_item_logistic_results ) )\n",
    "\n",
    "# Print contents of model_results\n",
    "print(pd.read_sql_query(\"SELECT * FROM model_Results;\", con))\n",
    "\n",
    "con.commit()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score on Test Data\n",
    "\n",
    "Even Lower Logistic seems to be pretty darn good, let's put in a submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create features for test submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"instacart.db\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Combine with features about current order\n",
    "cur.execute(\"DROP TABLE IF EXISTS features_1_test;\")\n",
    "cur.execute(\"CREATE TABLE features_1_test AS \"\n",
    "            \"SELECT A.user_id, \"\n",
    "            \" A.product_id, \"\n",
    "            \" A.total_previous_buys_item, \"\n",
    "            \" A.time_since_last_buy_item + B.days_since_prior_order as time_since_last_buy_item, \"\n",
    "            \" A.last_buy_day_of_week_item, \"\n",
    "            \" A.last_buy_Time_of_day_item, \"\n",
    "            \" A.last_order_number, \"\n",
    "            \" A.orders_in_history, \"\n",
    "            \" A.average_rebuy_duration, \"\n",
    "            \" A.average_rebuy_dow, \"\n",
    "            \" A.average_rebuy_hod, \"\n",
    "            \" B.order_id, \"\n",
    "            \" B.order_number, \"\n",
    "            \" B.order_dow, \"\n",
    "            \" B.order_hour_of_day, \"\n",
    "            \" B.days_since_prior_order \"\n",
    "            \"FROM features_1 A \"\n",
    "            \" INNER JOIN orders B \"\n",
    "            \" ON A.user_id = B.user_id \"\n",
    "            \"WHERE B.eval_set = 'test';\")\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary to house predictions\n",
    "user_item_logistic_lower_test = dict()\n",
    "\n",
    "# Total is 4.8M rows, let's break up into 10ths again. \n",
    "for i in range(10):\n",
    "    # Get data for predictions\n",
    "    conn = sqlite3.connect(\"instacart.db\")\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT * FROM features_1_test WHERE order_id % 10 =\" + str(i) + \" ;\")\n",
    "    test = cur.fetchall()\n",
    "    test_array = np.array(test)\n",
    "    conn.close()\n",
    "\n",
    "    # Put into array: \n",
    "    test_pred = test_array[:,[2,3,4,5,6,7,8,9,10,12,13,14,15]]\n",
    "    test_predictions = model_lr_sklearn.predict_proba(test_pred)\n",
    "\n",
    "    # Get order and products\n",
    "    test_lookup = test_array[:, [1, 11]]\n",
    "\n",
    "    test_assemble = np.column_stack((test_lookup, test_predictions))\n",
    "\n",
    "    # Assert: x_assemble column 0 == product id; 1 == order id; 2 == reorder prediction\n",
    "\n",
    "    # For each row: \n",
    "    for i in range(test_assemble.shape[0]):\n",
    "       # if it is a new order number, create a set\n",
    "        if int(test_assemble[i,1]) not in user_item_logistic_lower_test:\n",
    "            user_item_logistic_lower_test[int(test_assemble[i,1])] = set()\n",
    "        if test_assemble[i,3] > 0.2:\n",
    "            user_item_logistic_lower_test[int(test_assemble[i,1])].add(str(int(test_assemble[i,0])))\n",
    "    \n",
    "# Add \"None\" to orders with no items\n",
    "for y in [x for x in user_item_logistic_lower_test.keys() if len(user_item_logistic_lower_test[x]) == 0]:\n",
    "    user_item_logistic_lower_test[y].add(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_item_logistic_lower_test.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(474973, 16)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Write estimate\n",
    "f = open('copeland1.csv', 'w')\n",
    "f.write('order_id,products\\n')\n",
    "for order in user_item_logistic_lower_test:\n",
    "    f.write(str(order) + \",\")\n",
    "    for product in user_item_logistic_lower_test[order]:\n",
    "        f.write(product + \" \")\n",
    "    f.write('\\n')\n",
    "f.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "117px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
